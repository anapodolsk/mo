{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3v5HIUdDvY5"
      },
      "source": [
        "# HSE 2023: Введение в машинное обучение БИ 22/23\n",
        "\n",
        "## Домашнее задание № 3\n",
        "\n",
        "\n",
        "# Внимание!\n",
        "\n",
        "* Некоторые задания требуют значительного времени для выполнения (особенно часть с лемматизацией), поэтому **лучше приступить к выполнению домашнего задания как можно раньше** \n",
        "\n",
        "* Решения обязательно должны содержать комментарии, все полученные результаты должны сопровождаться выводами (для этого удобно использовать ячейки markdown)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "F7t9dYtdDvZC"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple, List\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "sns.set(style=\"darkgrid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIHtwV6vDvZD"
      },
      "source": [
        "## ЧАСТЬ 1: Логистическая регрессия"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7XKEWcVDvZD"
      },
      "source": [
        "Будем решать задачу бинарной классификации с помошью логистической регрессии.\n",
        "Для борьбы с переобучением будем использовать регуляризацию - комбинацию $L_1$ и $L_2$ (Elastic Net loss).\n",
        "\n",
        "Для каждого объекта обучающей выборки, заданного своим признаковым описанием $x_i\\in\\mathbb{R}^{K}$ (вектор из $k$ признаков), указан его класс $y_i$ (одно из двух значений). Параметрами модели являются смещение $w_0\\in\\mathbb{R}$ и веса $w\\in\\mathbb{R}^K$.\n",
        "\n",
        "Таким образом, оптимизируемый функционал (Elastic Net loss) можно записать в виде:\n",
        "\n",
        "$$L(w, w_0) = \\frac{1}{N} \\sum_{i=1}^N \\ln(1+\\exp(-y_i(w^\\top x_i+w_0))) + \\gamma \\|w\\|_1 + \\beta \\|w\\|_2^2$$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1eSuDKXFVZu"
      },
      "source": [
        "#### 1. [0.5 балла] Запишите формулу градиента Elastic Net loss (с выводом этой формулы, для форматирования лучше использовать Latex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zjH-YnPDvZD"
      },
      "source": [
        "##### Put your markdown formulas here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_lIccN_DvZE"
      },
      "source": [
        "#### 2. [0.25 балла] Реализуйте функцию вычисления Elastic Net loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QNfCtV5DvZE"
      },
      "outputs": [],
      "source": [
        "def loss(X, y, w: List[float], w0: float, gamma=1., beta=1.) -> float:\n",
        "    return # your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIVoC6UmDvZE"
      },
      "source": [
        "#### 3. [0.25 балла] Реализуйте функцию вычисления градиента"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWqBLGRADvZE"
      },
      "outputs": [],
      "source": [
        "def get_grad(X, y, w: List[float], w0: float, gamma=1., beta=1.) -> Tuple[List[float], float]:\n",
        "    grad_w0 = # your code here\n",
        "    grad_w = # your code here\n",
        "    \n",
        "    return grad_w, grad_w0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhOb8HrtDvZF"
      },
      "source": [
        "#### Проверьте корректность реализованных функций"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FxXTocHDvZF"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "X = np.random.multivariate_normal(np.arange(5), np.eye(5), size=10)\n",
        "y = np.random.binomial(1, 0.42, size=10)\n",
        "w, w0 = np.random.normal(size=5), np.random.normal()\n",
        "\n",
        "grad_w, grad_w0 = get_grad(X, y, w, w0)\n",
        "assert(np.allclose(grad_w,\n",
        "                   [-2.73262076, -1.87176281, 1.30051144, 2.53598941, -2.71198109],\n",
        "                   rtol=1e-2) & \\\n",
        "       np.allclose(grad_w0,\n",
        "                   -0.2078231418067844, \n",
        "                   rtol=1e-2)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbqLfcrRDvZF"
      },
      "source": [
        "####  4. [1 балл]  Реализуйте алгоритм градиентного спуска, поддержав различные критерии остановки: ограничение на количество итераций (max_iter) и ограничение на размер шага ([tolerance](https://nl.mathworks.com/help/optim/ug/tolerances-and-stopping-criteria.html)).\n",
        "\n",
        "Проверьте корректность реализации, визуализировав полученную разделяющую поверхность ([plot_decision_boundary](https://towardsdatascience.com/logistic-regression-from-scratch-in-python-ec66603592e2))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIgiwQkjDvZF"
      },
      "source": [
        "Ниже представлен шаблон класса, соответствующий стандартному API моделей sklearn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Thyeux0KDvZG"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erVmNR0PDvZG"
      },
      "outputs": [],
      "source": [
        "class Logit(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, beta=1.0, gamma=1.0, lr=1e-3, tolerance=0.01, max_iter=1000, random_state=42):  \n",
        "        self.beta = beta        \n",
        "        self.gamma = gamma\n",
        "        self.tolerance= tolerance\n",
        "        self.max_iter= max_iter\n",
        "        self.learning_rate = lr\n",
        "        self.random_state = random_state\n",
        "        # you may additional properties if you wish\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        # add weights and bias and optimize Elastic Net loss over (X,y) dataset\n",
        "        # save history of optimization steps\n",
        "        \n",
        "        # your code here\n",
        "\n",
        "        return self\n",
        "    \n",
        "    def predict(self, X):\n",
        "        # return vector of predicted labels for each object from X\n",
        "        # your code here\n",
        "\n",
        "        return predict\n",
        "        \n",
        "    def predict_proba(self, X):\n",
        "        return np.array([1 / (1 + np.exp(np.dot(X, self.w) + self.w0)),\\\n",
        "                         1 / (1 + np.exp(-np.dot(X, self.w) - self.w0))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SJX8Y6EDvZG"
      },
      "outputs": [],
      "source": [
        "# sample data to test your model\n",
        "from sklearn.datasets import make_classification\n",
        "X, y = make_classification(n_samples=180, n_features=2, n_redundant=0, n_informative=2,\n",
        "                               random_state=42, n_clusters_per_class=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u41kzwGTDvZH"
      },
      "outputs": [],
      "source": [
        "# a function to plot the decision boundary\n",
        "def plot_decision_boundary(model, X, y):\n",
        "    fig = plt.figure()\n",
        "    X1min, X2min = X.min(axis=0)\n",
        "    X1max, X2max = X.max(axis=0)\n",
        "    x1, x2 = np.meshgrid(np.linspace(X1min, X1max, 200),\n",
        "                         np.linspace(X2min, X2max, 200))\n",
        "    ypred = model.predict(np.c_[x1.ravel(), x2.ravel()])\n",
        "    ypred = ypred.reshape(x1.shape)\n",
        "    \n",
        "    plt.contourf(x1, x2, ypred, alpha=.4)\n",
        "    plt.scatter(X[:,0], X[:,1], c=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNuYbsAoDvZI"
      },
      "outputs": [],
      "source": [
        "model = Logit(0,0)\n",
        "y[y == 0] = -1\n",
        "model.fit(X, y)\n",
        "plot_decision_boundary(model, X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi4WRhcADvZI"
      },
      "source": [
        "#### 5. [0.25 балла] Постройте график зависимости значения функции потерь от номера итерации градиентного спуска."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyjMDAKuDvZI"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FhSCAv_DvZJ"
      },
      "source": [
        "## Часть 2: Support Vector Machines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYyGsSxEDvZJ"
      },
      "source": [
        "#### 6. [2 балла] Обучите [SVM](https://scikit-learn.org/stable/modules/svm.html) классификатор на том же наборе данных.\n",
        "\n",
        "Поисследуйте влияние гиперпараметров на качество обученной модели:\n",
        "+ Попробуйте несколько ядер: линейное, полиномиальное, RBF (и другие, если хотите). У некоторых ядер есть гиперметры: не забудьте поэкспериментировать с ними!\n",
        "+ Попробуйте разные коэффициенты регуляризации\n",
        "\n",
        "В качестве метрик качества будем использовать accuracy, roc_auc и f1 score. \n",
        "Постройте графики зависимости метрик качества от гиперпараметров.\n",
        "\n",
        "Какие выводы можно сделать на основе проведенных экспериментов? Насколько чувствительны ядра к гиперпараметрам? Какое ядро склонно приводить к переобучению? Насколько сильно на качество моделей влияет регуляризация?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nicu_O3IDvZK"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY8q6JdCDvZK"
      },
      "source": [
        "## Часть 3: Natural Language Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD4xKhYfDvZK"
      },
      "source": [
        "#### 7. [1.75 балла] Подготовка данных\n",
        "\n",
        "Подготовим набор данных, который будем использовать для бинарной и многоклассовой классификации.\n",
        "\n",
        "0. Выберите **шесть** любимых писателей-прозаиков (укажите, кого вы выбрали) и скачайте  <a href=\"https://www.kaggle.com/d0rj3228/russian-literature?select=prose\">данные</a> из раздела **проза**\n",
        "1. Подготовьте собственный датасет из выбранных авторов: \n",
        "    * разделите каждый текст на предложения так, чтобы представить данные в виде *предложение* and *автор* (каждая строка обучающего набора данных содержит ровно одно предложение и одного автора текста, откуда было взято это предложение);\n",
        "    * удалите короткие предложения (считаем, что предложение короткое, если в нем меньше 15 символов);\n",
        "    * зафиксируйте random state и случайно сформируйте выборку из предложений размера \"5k : 15k : 8k : 11k : 20k : 3k\" в разбивке по авторам соответственно;\n",
        "    \n",
        "    Пример полученных данных:\n",
        "    \n",
        "    <center> \n",
        "    <table>\n",
        "        <tr>\n",
        "            <th> sentence </th>\n",
        "            <th> author </th>\n",
        "        </tr> \n",
        "        <tr><td> Несколько лет тому назад в одном из своих поместий жил старинный русской барин, Кирила Петрович Троекуров. </td><td> Пушкин </td><td> \n",
        "        <tr><td> Уже более недели приезжий господин жил в городе, разъезжая по вечеринкам и обедам и таким образом проводя, как говорится, очень приятно время. </td><td> Гоголь </td><td> \n",
        "        <tr><td> ... </td><td> ... </td><td> \n",
        "        <tr><td> Я жил недорослем, гоняя голубей и играя в чехарду с дворовыми мальчишками. </td><td> Пушкин </td><td>         \n",
        "    </table>\n",
        "</center>\n",
        "     \n",
        "2. Предварительная обработка данных: \n",
        "    * токенизируйте предложения, удалите все стоп-слова (nltk.corpus.stopwords), знаки пунктуации (string.punctuation) и числа;\n",
        "    * преобразуйте все символы в нижний регистр и примените стемминг или лемматизацию (на свое усмотрение)\n",
        "    * постройте векторные представления предложений с помощью **bag of words** и **tf-idf** (используйте средства sklearn)\n",
        "    * обратите внимание на разницу между полученными векторными представлениями: чем отличаются векторы, полученные с помощью **bag of words** и **tf-idf**?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVStbeQ8DvZL"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuTi3rvnDvZL"
      },
      "source": [
        "###  Бинарная классификация\n",
        "\n",
        "#### 8. [2 балла] Обучете логистическую регрессию (написанную вами реализацию) и SVC (реализацию SVM из sklearn) \n",
        "\n",
        "* выберите **двух** любых авторов из сформированного в задании 7 набора данных\n",
        "* проверьте, сбалансированны ли классы\n",
        "* разделите данные на тренировочную и тестовую выборки, выделив под test 0.3 всех предложений (не забудьте зафиксировать random state)\n",
        "* с помощью GridSearchCV найдите оптимальные гиперпараметры  моделей (согласно метрике F1 score) и используйте найденные гиперпараметры при выполнении следующих пунктов задания\n",
        "* постройте графики зависимости F1 score от гиперпараметров\n",
        "* постройте confusion matrix для train и test\n",
        "* вычислите другие метрики качества для обученной модели (удобно воспользоваться реализацией из sklearn) \n",
        "* проанализируйте полученные значения метрик, сделайте вывод о качестве обученной модели\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZUP1HqFDvZL"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G1kt0qbDvZL"
      },
      "source": [
        "#### 9. [1 балл] ROC AUC\n",
        "\n",
        "Можно контролировать статистические ошибки первого и второго типов, используя различные пороговые значения для определения классов. Постройте ROC-кривые для логистической регрессии и SVC. Подберите такой порог, чтобы частота ложноположительных срабатываний составляла не более 30%. Обратите внимание на параметр `thresholds` в sklearn roc_curve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZ2GZ8-uDvZL"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-qubaK4DvZM"
      },
      "source": [
        "### Многоклассовая классификация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJQone-LDvZM"
      },
      "source": [
        "#### 10. [1 балл] Примените <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsOneClassifier.html\">OneVsOneClassifier</a> из sklearn к реализованной логистической регресии для того, чтобы получить многоклассовый линейный классификатор:\n",
        "* используйте набор данных, подготовленный в задании 7\n",
        "* разделите данные на тренировочную и тестовую выборки, выделив под test 0.3 всех предложений (не забудьте зафиксировать random state)\n",
        "* с помощью GridSearchCV найдите оптимальные гиперпараметры моделей (согласно метрике F1 score)\n",
        "* постройте confusion matrix для train и test\n",
        "* вычислите другие метрики качества для обученной модели (удобно воспользоваться реализацией из sklearn)\n",
        "* проанализируйте полученные значения метрик, сделайте вывод о качестве обученной модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4lR8qJ7DvZM"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}