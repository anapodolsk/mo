{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBrDXMdDy-Qn"
      },
      "source": [
        "# HSE 2023: Введение в машинное обучение БИ 22/23\n",
        "\n",
        "## ДЗ 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Внимание!\n",
        "Если в задании просят объяснить что-либо, то это значит, что требуется письменный ответ, который является частью задания и оценивается\n",
        "\n",
        "Мы только принимаем ipynb ноутбуки. Если вы используете Google Colab, то вам необходимо скачать ноутбук перед сдачей ДЗ\n"
      ],
      "metadata": {
        "id": "RXXi5K1mf41d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-26T16:48:20.566549Z",
          "start_time": "2020-09-26T16:48:19.893995Z"
        },
        "id": "mSR-a9vVy-Qp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "from sklearn import datasets\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.regression.linear_model import OLSResults\n",
        "from math import sqrt\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "sns.set(style=\"darkgrid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUjuv9Qty-Qq"
      },
      "source": [
        "### Данные\n",
        "\n",
        "Для этого ДЗ мы будем использовать датасет по ценам бриллиантов из seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHWSWTXDy-Qq"
      },
      "outputs": [],
      "source": [
        "data = sns.load_dataset('diamonds')\n",
        "\n",
        "y = data.price\n",
        "X = data.drop(['price'], axis=1)\n",
        "columns = data.drop(['price'], axis=1).columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K81w8s35y-Qq"
      },
      "source": [
        "## Линейная регрессия"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYgEN-FMy-Qr"
      },
      "source": [
        "#### 0. [0.25 балла] Закодируйте категориальные признаки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IrSlQaWy-Qr"
      },
      "outputs": [],
      "source": [
        "# ваш код здесь \n",
        "#╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dVwP45Gy-Qr"
      },
      "source": [
        "#### 1. [0.25 балла] Разбейте данные на train и test с пропорцией 80:20 и random_state=17. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7z8TIh5y-Qs"
      },
      "outputs": [],
      "source": [
        "# ваш код здесь \n",
        "#╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7daIQRfKy-Qs"
      },
      "source": [
        "#### 2. [1 балл] Обучите модели на train'е используя библиотеку StatsModels и примените ее к test'у; используйте $RMSE$ и $R ^ 2$ в качестве метрики качества. Попробуйте также применить реализации линейной регрессии из sklearn:\n",
        "\n",
        "* [`LinearRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html);\n",
        "* [`Ridge`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) with $\\alpha = 0.01$;\n",
        "* [`Lasso`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) with $\\alpha = 0.01$\n",
        "* [`ElasticNet`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html) with $\\alpha = 0.01$, $l_{1}$_$ratio = 0.6$\n",
        "\n",
        "Не забывайте скейлить данные с помощью StandardScaler перед обучением моделей! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bkbr5iFCy-Qs"
      },
      "outputs": [],
      "source": [
        "# ваш код здесь \n",
        "#╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69JOftKRy-Qt"
      },
      "source": [
        "#### 3. [1 балл] Исследуйте значения параметров полученных моделей и проверьте какие веса получились нулевыми. Прокомментируйте значимость коэффициентов, обшую значимость модели и остальные факторы из результирующей таблицы "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Np1biYQ7y-Qt"
      },
      "outputs": [],
      "source": [
        "# ваш код здесь \n",
        "#╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLcvGlUZy-Qt"
      },
      "source": [
        "#### 4. [1 балл] Реализуйте один из алгоритмов отбора признаков (Elimination by P-value, Forward elimination, Backward elimination), сделайте выводы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnrbRbkwy-Qt"
      },
      "outputs": [],
      "source": [
        "# your code here \n",
        "#╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df0eQLdNy-Qt"
      },
      "source": [
        "#### 5. [1 балл] Найдите лучший (по RMSE) $\\alpha$ для регрессиии Lasso, используя кросс-валидациб на 4 фолда. Вы должны выбрать значение из промежутка $[10^{-4}, 10^{3}]$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPoT3YHqy-Qt"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "#╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1PKinJUy-Qt"
      },
      "source": [
        "## Градиентный спуск\n",
        "\n",
        "#### 6. [3.5 балла] Имплементируйте  Ridge регрессию для MSE loss, обученную на градиентом спуске.\n",
        "\n",
        "\n",
        "Все вычисления должны быть векторизованы, а циклы Python можно использовать только для итераций градиентного спуска. В качестве критерия остановки необходимо использовать (одновременно):\n",
        "\n",
        "* проверка абсолютной нормы разницы весов на двух соседних итерациях (например, меньше некоторого малого числа порядка $10^{-6}$, заданного параметром `tolerance`);\n",
        "\n",
        "* достижение максимального количества итераций (например, 10000, заданного параметром `max_iter`).\n",
        "\n",
        "Вам необходимо выполнить:\n",
        "\n",
        "* Полный градиентный спуск:\n",
        "\n",
        "$$\n",
        "w_{k + 1} = w_{k} - \\eta_{k} \\nabla_{w} Q(w_{k}).\n",
        "$$\n",
        "\n",
        "* Стохастический градиентный спуск:\n",
        "\n",
        "$$\n",
        "w_{k + 1} = w_{k} - \\eta_{k} \\nabla_{w} q_{i_{k}}(w_{k}).\n",
        "$$\n",
        "\n",
        "$\\nabla_{w} q_{i_{k}}(w_{k}) \\, $ является оценкой градиента по набору объектов, выбранных случайным образом.\n",
        "\n",
        "* Momentum method:\n",
        "\n",
        "$$\n",
        "h_0 = 0, \\\\\n",
        "h_{k + 1} = \\alpha h_{k} + \\eta_k \\nabla_{w} Q(w_{k}), \\\\\n",
        "w_{k + 1} = w_{k} - h_{k + 1}.\n",
        "$$\n",
        "\n",
        "* Adagrad method:\n",
        "\n",
        "$$\n",
        "G_0 = 0, \\\\\n",
        "G_{k + 1} = G_{k} + (\\nabla_{w} Q(w_{k+1}))^2, \\\\\n",
        "w_{k + 1} = w_{k} - \\eta * \\frac{\\nabla_{w} Q(w_{k+1})}{\\sqrt{G_{k+1} + \\epsilon}}.\n",
        "$$\n",
        "\n",
        "Чтобы убедиться, что процесс оптимизации действительно выполняется, мы будем использовать атрибут класса `loss_history`. После вызова метода fit он должен содержать значения функции потерь для всех итераций, начиная с первой (до первого шага по антиградиенту).\n",
        "\n",
        "\n",
        "Вам нужно инициализировать веса случайным вектором из нормального распределения. Ниже приведен шаблон, который должен содержать код, реализующий все варианты моделей."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oI39UzCLy-Qu"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "class LinReg(BaseEstimator):\n",
        "    def __init__(self, delta=1.0, gd_type='Momentum', \n",
        "                 tolerance=1e-4, max_iter=1000, w0=None, eta=1e-2, alpha=1e-3):\n",
        "        \"\"\"\n",
        "        gd_type: str\n",
        "            'GradientDescent', 'StochasticDescent', 'Momentum', 'Adagrad'\n",
        "        delta: float\n",
        "            proportion of object in a batch (for stochastic GD)\n",
        "        tolerance: float\n",
        "            for stopping gradient descent\n",
        "        max_iter: int\n",
        "            maximum number of steps in gradient descent\n",
        "        w0: np.array of shape (d)\n",
        "            init weights\n",
        "        eta: float\n",
        "            learning rate\n",
        "        alpha: float\n",
        "            momentum coefficient\n",
        "        reg_cf: float\n",
        "            regularization coefficient\n",
        "        epsilon: float\n",
        "            numerical stability\n",
        "        \"\"\"\n",
        "        \n",
        "        self.delta = delta\n",
        "        self.gd_type = gd_type\n",
        "        self.tolerance = tolerance\n",
        "        self.max_iter = max_iter\n",
        "        self.w0 = w0\n",
        "        self.alpha = alpha\n",
        "        self.w = None\n",
        "        self.eta = eta\n",
        "        self.loss_history = None # list of loss function values at each training iteration\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array of shape (l, d)\n",
        "        y: np.array of shape (l)\n",
        "        ---\n",
        "        output: self\n",
        "        \"\"\"\n",
        "        self.loss_history = []\n",
        "\n",
        "        return self\n",
        "    \n",
        "    def predict(self, X):\n",
        "        if self.w is None:\n",
        "            raise Exception('Not trained yet')\n",
        "        \n",
        "        pass\n",
        "    \n",
        "    def calc_gradient(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array of shape (l, d) (l can be equal to 1 if stochastic)\n",
        "        y: np.array of shape (l)\n",
        "        ---\n",
        "        output: np.array of shape (d)\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def calc_loss(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array of shape (l, d)\n",
        "        y: np.array of shape (l)\n",
        "        ---\n",
        "        output: float \n",
        "        \"\"\" \n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QQJEjGVy-Qu"
      },
      "source": [
        "#### 7. [1 балл] Натренируйте и провалидируйте \"ручные\" модели на тех же даннных, сравните качество с моделями из Sklearn и StatsModels. Исследуйте влияние параметров `max_iter` и `alpha` на процесс оптимизации. Соответствует ли оно вашим ожиданиям?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIJNcxt_y-Qu"
      },
      "outputs": [],
      "source": [
        "# your code here \n",
        "#╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqYtVqv-y-Qu"
      },
      "source": [
        "#### 8. [1 балл] Постройте графики (там же) зависимости значения функции потерь от номера итерации для всех моделей (полного градиентого спуска, стохастического гс, Momentum и Adagrad). Сделайте выводы о скорости сходимости различных модификаций градиентного спуска.\n",
        "\n",
        "\n",
        "Не забывайте о том, как должен выглядеть *красивый* график!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xbwhu8BSy-Qu"
      },
      "outputs": [],
      "source": [
        "# your code here \n",
        "#╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5z22Sg9y-Qu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}